{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T18:57:36.476095Z",
     "start_time": "2020-11-05T18:57:31.741478Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "import code\n",
    "import urllib\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import tensorflow.python.platform\n",
    "import matplotlib.image as mpimg\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T18:57:36.562269Z",
     "start_time": "2020-11-05T18:57:36.478886Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T18:57:36.693949Z",
     "start_time": "2020-11-05T18:57:36.566770Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.append('./')\n",
    "from helpers.helpers import *\n",
    "from helpers.mask_to_submission import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T18:57:36.764949Z",
     "start_time": "2020-11-05T18:57:36.697194Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_CHANNELS = 3  # RGB images\n",
    "PIXEL_DEPTH = 255\n",
    "NUM_LABELS = 2\n",
    "TRAINING_SIZE = 80\n",
    "VALIDATION_SIZE = 5  # Size of the validation set.\n",
    "SEED = 66478  # Set to None for random seed.\n",
    "BATCH_SIZE = 16  # 64\n",
    "NUM_EPOCHS = 10\n",
    "RESTORE_MODEL = False  # If True, restore existing model instead of training a new one\n",
    "RECORDING_STEP = 0\n",
    "\n",
    "# Set image patch size in pixels\n",
    "# IMG_PATCH_SIZE should be a multiple of 4\n",
    "# image size should be an integer multiple of this number!\n",
    "IMG_PATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T19:24:31.064890Z",
     "start_time": "2020-11-05T19:24:24.322395Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 training images\n",
      "Loaded 100 groudtruth images\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'data/training/'\n",
    "train_data_filename = data_dir + 'images/'\n",
    "train_labels_filename = data_dir + 'groundtruth/' \n",
    "\n",
    "# Extract patches into numpy arrays. Dim: (nb patch, 16, 16, 3)\n",
    "training_data = extract_data(train_data_filename, 100)\n",
    "training_labels = extract_labels(train_labels_filename, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T19:24:31.261976Z",
     "start_time": "2020-11-05T19:24:31.067813Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 16, 16, 3)\n",
      "(12500, 16, 16, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_validation, y_train, y_validation = train_test_split(training_data, training_labels,\\\n",
    "                                                    train_size= TRAINING_SIZE/100, random_state=SEED)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T19:17:17.191957Z",
     "start_time": "2020-11-05T19:17:17.106821Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-65a3052ae8ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m  \u001b[0;31m# road\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mc0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "num_epochs = NUM_EPOCHS\n",
    "\n",
    "c0 = 0  # bgrd\n",
    "c1 = 0  # road\n",
    "for i in range(len(y_train)):\n",
    "    if y_train[i][0] == 1:\n",
    "        c0 = c0 + 1\n",
    "    else:\n",
    "        c1 = c1 + 1\n",
    "print('Number of data points per class: c0 = ' + str(c0) + ' c1 = ' + str(c1))\n",
    "\n",
    "print('Balancing training data...')\n",
    "min_c = min(c0, c1)\n",
    "idx0 = [i for i, j in enumerate(y_train) if j[0] == 1]\n",
    "idx1 = [i for i, j in enumerate(y_train) if j[1] == 1]\n",
    "new_indices = idx0[0:min_c] + idx1[0:min_c]\n",
    "print(len(new_indices))\n",
    "print(X_train.shape)\n",
    "X_train = X_train[new_indices, :, :, :]\n",
    "y_train = y_train[new_indices]\n",
    "\n",
    "train_size = y_train.shape[0]\n",
    "\n",
    "c0 = 0\n",
    "c1 = 0\n",
    "for i in range(len(y_train)):\n",
    "    if y_train[i][0] == 1:\n",
    "        c0 = c0 + 1\n",
    "    else:\n",
    "        c1 = c1 + 1\n",
    "print('Number of data points per class: c0 = ' + str(c0) + ' c1 = ' + str(c1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T19:17:20.381184Z",
     "start_time": "2020-11-05T19:17:20.313096Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 16, 16, 3)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T18:57:42.968972Z",
     "start_time": "2020-11-05T18:57:42.896467Z"
    }
   },
   "outputs": [],
   "source": [
    "if RESTORE_MODEL:\n",
    "    # It can be used to reconstruct the model identically.\n",
    "    model = models.load_model(\"U-net_save/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T15:12:30.012573Z",
     "start_time": "2020-11-04T15:12:29.644147Z"
    }
   },
   "outputs": [],
   "source": [
    "# if not RESTORE_MODEL:\n",
    "#     def down_block(model, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "#         model.add(layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\"))\n",
    "#         model.add(layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\"))\n",
    "#         model.add(layers.MaxPool2D((2, 2), (2, 2)))\n",
    "\n",
    "#     def up_block(model, skip, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "#         model.add(layers.UpSampling2D((2, 2)))\n",
    "#         model.add(layers.Concatenate()([us, skip]))\n",
    "#         model.add(layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\"))\n",
    "#         model.add(layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\"))\n",
    "\n",
    "#     def bottleneck(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "#         model.add(layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\"))\n",
    "#         model.add(layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\"))\n",
    "\n",
    "#     f = [16, 32, 64, 128, 256]\n",
    "#     model = models.Sequential(\n",
    "#         down_block()\n",
    "#     )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T19:17:25.483458Z",
     "start_time": "2020-11-05T19:17:25.409665Z"
    }
   },
   "outputs": [],
   "source": [
    "def down_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    c = layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(x)\n",
    "    c = layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
    "    p = layers.MaxPool2D((2, 2), (2, 2))(c)\n",
    "    return c, p\n",
    "\n",
    "def up_block(x, skip, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    us = layers.UpSampling2D((2, 2))(x)\n",
    "    concat = layers.Concatenate()([us, skip])\n",
    "    c = layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(concat)\n",
    "    c = layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
    "    return c\n",
    "\n",
    "def bottleneck(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    c = layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(x)\n",
    "    c = layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T19:25:31.578049Z",
     "start_time": "2020-11-05T19:25:31.497194Z"
    }
   },
   "outputs": [],
   "source": [
    "def UNet():\n",
    "    f = [16, 32, 64, 128, 256]\n",
    "    inputs = layers.Input((IMG_PATCH_SIZE, IMG_PATCH_SIZE, 3))\n",
    "    \n",
    "    p0 = inputs\n",
    "    c1, p1 = down_block(p0, f[0]) #128 -> 64\n",
    "    c2, p2 = down_block(p1, f[1]) #64 -> 32\n",
    "    c3, p3 = down_block(p2, f[2]) #32 -> 16\n",
    "    c4, p4 = down_block(p3, f[3]) #16->8\n",
    "    \n",
    "    bn = bottleneck(p4, f[4])\n",
    "    \n",
    "    u1 = up_block(bn, c4, f[3]) #8 -> 16\n",
    "    u2 = up_block(u1, c3, f[2]) #16 -> 32\n",
    "    u3 = up_block(u2, c2, f[1]) #32 -> 64\n",
    "    u4 = up_block(u3, c1, f[0]) #64 -> 128\n",
    "    \n",
    "    a0 = layers.Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")(u4)\n",
    "    a1 = layers.Flatten()(a0)\n",
    "    a2 = layers.Dense(64, activation='relu')(a1)\n",
    "    outputs = layers.Dense(2)(a2)\n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T19:25:32.315142Z",
     "start_time": "2020-11-05T19:25:31.979499Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(None, 16, 16, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 16, 16, 16)   448         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 16, 16, 16)   2320        conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling2D) (None, 8, 8, 16)     0           conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 8, 8, 32)     4640        max_pooling2d_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 8, 8, 32)     9248        conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling2D) (None, 4, 4, 32)     0           conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 4, 4, 64)     18496       max_pooling2d_29[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 4, 4, 64)     36928       conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling2D) (None, 2, 2, 64)     0           conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 2, 2, 128)    73856       max_pooling2d_30[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 2, 2, 128)    147584      conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling2D) (None, 1, 1, 128)    0           conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 1, 1, 256)    295168      max_pooling2d_31[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 1, 1, 256)    590080      conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_28 (UpSampling2D) (None, 2, 2, 256)    0           conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 2, 2, 384)    0           up_sampling2d_28[0][0]           \n",
      "                                                                 conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 2, 2, 128)    442496      concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 2, 2, 128)    147584      conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_29 (UpSampling2D) (None, 4, 4, 128)    0           conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 4, 4, 192)    0           up_sampling2d_29[0][0]           \n",
      "                                                                 conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 4, 4, 64)     110656      concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 4, 4, 64)     36928       conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_30 (UpSampling2D) (None, 8, 8, 64)     0           conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 8, 8, 96)     0           up_sampling2d_30[0][0]           \n",
      "                                                                 conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 8, 8, 32)     27680       concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 8, 8, 32)     9248        conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_31 (UpSampling2D) (None, 16, 16, 32)   0           conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 16, 16, 48)   0           up_sampling2d_31[0][0]           \n",
      "                                                                 conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 16, 16, 16)   6928        concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 16, 16, 16)   2320        conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 16, 16, 1)    17          conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 256)          0           conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           16448       flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            130         dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 1,979,203\n",
      "Trainable params: 1,979,203\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = UNet()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T20:06:15.245726Z",
     "start_time": "2020-11-05T19:25:36.266590Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 231s 148ms/step - loss: 0.5439 - accuracy: 0.7405 - val_loss: 0.5204 - val_accuracy: 0.7405\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 234s 150ms/step - loss: 0.5040 - accuracy: 0.7447 - val_loss: 0.4754 - val_accuracy: 0.7600\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 213s 136ms/step - loss: 0.4326 - accuracy: 0.7876 - val_loss: 0.4190 - val_accuracy: 0.7969\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 210s 135ms/step - loss: 0.4041 - accuracy: 0.8042 - val_loss: 0.3978 - val_accuracy: 0.8074\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 217s 139ms/step - loss: 0.3884 - accuracy: 0.8136 - val_loss: 0.4004 - val_accuracy: 0.8038\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 229s 147ms/step - loss: 0.3806 - accuracy: 0.8190 - val_loss: 0.3853 - val_accuracy: 0.8174\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 258s 165ms/step - loss: 0.3704 - accuracy: 0.8244 - val_loss: 0.3883 - val_accuracy: 0.8234\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 276s 176ms/step - loss: 0.3666 - accuracy: 0.8253 - val_loss: 0.3911 - val_accuracy: 0.8102\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 292s 187ms/step - loss: 0.3559 - accuracy: 0.8318 - val_loss: 0.3628 - val_accuracy: 0.8294\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 276s 177ms/step - loss: 0.3468 - accuracy: 0.8397 - val_loss: 0.3731 - val_accuracy: 0.8269\n"
     ]
    }
   ],
   "source": [
    "if not RESTORE_MODEL: \n",
    "    model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    history = model.fit(X_train, y_train, epochs = NUM_EPOCHS ,validation_data=(X_validation, y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T15:36:07.202726Z",
     "start_time": "2020-11-04T15:36:05.671002Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: handmade_cnn_save/assets\n"
     ]
    }
   ],
   "source": [
    "if not RESTORE_MODEL:\n",
    "    model.save(\"U-net_save/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T15:31:17.904771Z",
     "start_time": "2020-11-04T15:31:11.581527Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error rate: 9.66%\n"
     ]
    }
   ],
   "source": [
    "pred_train = model.predict(X_train)\n",
    "print(\"Training error rate: {:.2f}%\".format(error_rate(pred_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T15:29:40.055957Z",
     "start_time": "2020-11-04T15:29:38.082308Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation error rate: 17.78%\n"
     ]
    }
   ],
   "source": [
    "pred_validation = model.predict(X_validation)\n",
    "print(\"Validation error rate: {:.2f}%\".format(error_rate(pred_validation, y_validation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T15:33:21.635243Z",
     "start_time": "2020-11-04T15:33:21.355409Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7976718867766519"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1_score(y_train, pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T15:42:12.295880Z",
     "start_time": "2020-11-04T15:41:40.987577Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running prediction on training set\n"
     ]
    }
   ],
   "source": [
    "print(\"Running prediction on training set\")\n",
    "prediction_training_dir = \"predictions_training/\"\n",
    "if not os.path.isdir(prediction_training_dir):\n",
    "    os.mkdir(prediction_training_dir)\n",
    "for i in range(1, TRAINING_SIZE + 1):\n",
    "    pimg = get_prediction_with_groundtruth(model, train_data_filename, i)\n",
    "    Image.fromarray(pimg).save(prediction_training_dir + \"prediction_\" + str(i) + \".png\")\n",
    "    oimg = get_prediction_with_overlay(model, train_data_filename, i)\n",
    "    oimg.save(prediction_training_dir + \"overlay_\" + str(i) + \".png\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T16:09:16.623322Z",
     "start_time": "2020-11-04T16:09:02.803475Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running prediction on test set\n"
     ]
    }
   ],
   "source": [
    "predict_test_masks(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T16:17:26.132182Z",
     "start_time": "2020-11-04T16:17:23.158897Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions_test/test_14.png\n",
      "predictions_test/test_28.png\n",
      "predictions_test/test_29.png\n",
      "predictions_test/test_15.png\n",
      "predictions_test/test_9.png\n",
      "predictions_test/test_17.png\n",
      "predictions_test/test_16.png\n",
      "predictions_test/test_8.png\n",
      "predictions_test/test_12.png\n",
      "predictions_test/test_13.png\n",
      "predictions_test/test_39.png\n",
      "predictions_test/test_11.png\n",
      "predictions_test/test_10.png\n",
      "predictions_test/test_38.png\n",
      "predictions_test/test_48.png\n",
      "predictions_test/test_49.png\n",
      "predictions_test/test_42.png\n",
      "predictions_test/test_43.png\n",
      "predictions_test/test_41.png\n",
      "predictions_test/test_40.png\n",
      "predictions_test/test_44.png\n",
      "predictions_test/test_50.png\n",
      "predictions_test/test_45.png\n",
      "predictions_test/test_47.png\n",
      "predictions_test/test_46.png\n",
      "predictions_test/test_3.png\n",
      "predictions_test/test_35.png\n",
      "predictions_test/test_21.png\n",
      "predictions_test/test_20.png\n",
      "predictions_test/test_34.png\n",
      "predictions_test/test_2.png\n",
      "predictions_test/test_22.png\n",
      "predictions_test/test_36.png\n",
      "predictions_test/test_37.png\n",
      "predictions_test/test_23.png\n",
      "predictions_test/test_1.png\n",
      "predictions_test/test_5.png\n",
      "predictions_test/test_27.png\n",
      "predictions_test/test_33.png\n",
      "predictions_test/test_32.png\n",
      "predictions_test/test_26.png\n",
      "predictions_test/test_4.png\n",
      "predictions_test/test_6.png\n",
      "predictions_test/test_18.png\n",
      "predictions_test/test_30.png\n",
      "predictions_test/test_24.png\n",
      "predictions_test/test_25.png\n",
      "predictions_test/test_31.png\n",
      "predictions_test/test_19.png\n",
      "predictions_test/test_7.png\n"
     ]
    }
   ],
   "source": [
    "masks_to_submission(\"submission.csv\", \"predictions_test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
