{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "PzRKgXa8Fwc0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "import code\n",
    "import urllib\n",
    "import importlib\n",
    "import tensorflow.python.platform\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "_hxY-fQOGkon"
   },
   "outputs": [],
   "source": [
    "COLAB = False\n",
    "BRANCH = 'main'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "FBdjGm_UPHP1"
   },
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    drive_path = '/content/drive/Shareddrives/ML_Road_Segmentation/CS-433-project-2/project_road_segmentation'\n",
    "    os.chdir(drive_path)\n",
    "    from helpers.colab import mount_and_pull\n",
    "    BRANCH_NAME = BRANCH\n",
    "    mount_and_pull(BRANCH_NAME, drive, os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uMaqi7NPFwc1",
    "outputId": "5c9ee4cb-2741-4c00-d0bb-a4d8ab6b9bde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from helpers.image_processing import *\n",
    "from helpers.file_manipulation import *\n",
    "from helpers.constants import *\n",
    "from helpers.prediction_checking import *\n",
    "from helpers.machine_learning import *\n",
    "from helpers.loss_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "KCVUhXFuGkop"
   },
   "outputs": [],
   "source": [
    "RESTORE_MODEL = False  # If True, restore existing model instead of training a new one\n",
    "SAVE_MODEL = False\n",
    "GENERATE_PREDICTION = False  # If True, will generate a CSV to submit on AICrowd\n",
    "\n",
    "MODEL_NAME = 'cnn_6conv'  # For now, cnn, unet-1, unet-2\n",
    "SAVE_DIR = MODELS_SAVE_DIR + MODEL_NAME + '/'\n",
    "\n",
    "NUM_EPOCHS = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "kL0u2TT-Gkop"
   },
   "outputs": [],
   "source": [
    "mod = importlib.import_module('models.' + MODEL_NAME)\n",
    "model_function = getattr(mod, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X5Ug1VniHb91",
    "outputId": "c4064b73-a147-42d0-b907-01e96687b11e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 112.34it/s]\n",
      " 10%|█         | 10/100 [00:00<00:00, 97.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 training images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 108.50it/s]\n",
      " 11%|█         | 11/100 [00:00<00:00, 105.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 training images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 110.74it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 training images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 96.46it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 training images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 96.83it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 training images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 478.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 groudtruth images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 245.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 groudtruth images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 210.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 groudtruth images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 225.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 groudtruth images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 247.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 groudtruth images\n"
     ]
    }
   ],
   "source": [
    "from legacy.old_helpers import *\n",
    "data_dir = 'data/training/'\n",
    "train_data_filename = data_dir + 'images/'\n",
    "train_labels_filename = data_dir + 'groundtruth/' \n",
    "\n",
    "# Extract pixel patches into numpy arrays. Dim: (nb patch, 16, 16, 3)\n",
    "\n",
    "training_data = extract_data(train_data_filename, 100)\n",
    "for transformation in ['mix', 'rotation', 'flip', 'shift']:\n",
    "    training_data = np.vstack([training_data, extract_data(f'data/generated/{transformation}/images/', 100)])\n",
    "training_labels = extract_labels(train_labels_filename, 100)\n",
    "for transformation in ['mix', 'rotation', 'flip', 'shift']:\n",
    "    training_labels = np.vstack([training_labels, extract_labels(f'data/generated/{transformation}/groundtruth/', 100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ltjrwFAHoVu",
    "outputId": "cedfb794-18ad-428a-cdd7-574707dec266"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 16, 16, 3)\n",
      "(62000, 16, 16, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#Create training sets and validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(training_data, training_labels,\\\n",
    "                                                    train_size= int(len(training_data) * 0.8), random_state=SEED)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WyMhDusfFwc3",
    "outputId": "f65702a4-b2f3-4b7e-d52f-5dcf3a0b770b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data/training/images/: 100%|██████████| 100/100 [00:03<00:00, 29.57it/s]\n",
      "Loading data/training/groundtruth/: 100%|██████████| 100/100 [00:00<00:00, 295.91it/s]\n",
      "Loading data/generated/shift/images/: 100%|██████████| 100/100 [00:02<00:00, 43.98it/s]\n",
      "Loading data/generated/shift/groundtruth/: 100%|██████████| 100/100 [00:00<00:00, 168.90it/s]\n",
      "Loading data/generated/flip/images/: 100%|██████████| 100/100 [00:02<00:00, 38.74it/s]\n",
      "Loading data/generated/flip/groundtruth/: 100%|██████████| 100/100 [00:00<00:00, 158.07it/s]\n",
      "Loading data/generated/mix/images/: 100%|██████████| 100/100 [00:02<00:00, 44.04it/s]\n",
      "Loading data/generated/mix/groundtruth/: 100%|██████████| 100/100 [00:01<00:00, 84.56it/s]\n",
      "Loading data/generated/rotation/images/: 100%|██████████| 100/100 [00:02<00:00, 39.28it/s]\n",
      "Loading data/generated/rotation/groundtruth/: 100%|██████████| 100/100 [00:00<00:00, 102.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape :  (500, 400, 400, 3)\n",
      "Training labels shape :  (500, 400, 400)\n"
     ]
    }
   ],
   "source": [
    "# X_train, X_test, y_train, y_test = get_train_test(data_augmentation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cBE8XdxDFwc4",
    "outputId": "071fb4f0-6e92-44b8-a7bc-5a922afdf06e",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "6250/6250 [==============================] - 44s 7ms/step - loss: 0.6422 - precision_4: 0.6636 - recall_4: 0.6636 - dice_coef: 0.5680 - val_loss: 0.6148 - val_precision_4: 0.6636 - val_recall_4: 0.6636 - val_dice_coef: 0.5905\n",
      "Epoch 2/250\n",
      "6250/6250 [==============================] - 44s 7ms/step - loss: 0.6491 - precision_4: 0.6582 - recall_4: 0.6582 - dice_coef: 0.5729 - val_loss: 0.6150 - val_precision_4: 0.6636 - val_recall_4: 0.6636 - val_dice_coef: 0.5677\n",
      "Epoch 3/250\n",
      "6250/6250 [==============================] - 44s 7ms/step - loss: 8.5830 - precision_4: 0.4162 - recall_4: 0.4162 - dice_coef: 0.4181 - val_loss: 10.1785 - val_precision_4: 0.3364 - val_recall_4: 0.3364 - val_dice_coef: 0.3466\n",
      "Epoch 4/250\n",
      "6250/6250 [==============================] - 43s 7ms/step - loss: 9.9154 - precision_4: 0.3535 - recall_4: 0.3535 - dice_coef: 0.3635 - val_loss: 10.1784 - val_precision_4: 0.3364 - val_recall_4: 0.3364 - val_dice_coef: 0.3466\n",
      "Epoch 5/250\n",
      "6250/6250 [==============================] - 43s 7ms/step - loss: 10.2317 - precision_4: 0.3329 - recall_4: 0.3329 - dice_coef: 0.3432 - val_loss: 10.1783 - val_precision_4: 0.3364 - val_recall_4: 0.3364 - val_dice_coef: 0.3466\n",
      "Epoch 6/250\n",
      "6250/6250 [==============================] - 43s 7ms/step - loss: 10.2305 - precision_4: 0.3330 - recall_4: 0.3330 - dice_coef: 0.3432 - val_loss: 10.1783 - val_precision_4: 0.3364 - val_recall_4: 0.3364 - val_dice_coef: 0.3466\n",
      "Epoch 7/250\n",
      "6250/6250 [==============================] - 44s 7ms/step - loss: 7.4091 - precision_4: 0.5169 - recall_4: 0.5169 - dice_coef: 0.5244 - val_loss: 5.1588 - val_precision_4: 0.6636 - val_recall_4: 0.6636 - val_dice_coef: 0.6688\n",
      "Epoch 8/250\n",
      "6250/6250 [==============================] - 43s 7ms/step - loss: 5.1057 - precision_4: 0.6671 - recall_4: 0.6671 - dice_coef: 0.6723 - val_loss: 5.1588 - val_precision_4: 0.6636 - val_recall_4: 0.6636 - val_dice_coef: 0.6688\n",
      "Epoch 9/250\n",
      "6250/6250 [==============================] - 43s 7ms/step - loss: 5.1055 - precision_4: 0.6671 - recall_4: 0.6671 - dice_coef: 0.6723 - val_loss: 5.1588 - val_precision_4: 0.6636 - val_recall_4: 0.6636 - val_dice_coef: 0.6688\n",
      "Epoch 10/250\n",
      "6250/6250 [==============================] - 43s 7ms/step - loss: 5.1057 - precision_4: 0.6671 - recall_4: 0.6671 - dice_coef: 0.6723 - val_loss: 5.1588 - val_precision_4: 0.6636 - val_recall_4: 0.6636 - val_dice_coef: 0.6688\n",
      "Epoch 11/250\n",
      "6250/6250 [==============================] - 43s 7ms/step - loss: 5.1056 - precision_4: 0.6671 - recall_4: 0.6671 - dice_coef: 0.6723 - val_loss: 5.1588 - val_precision_4: 0.6636 - val_recall_4: 0.6636 - val_dice_coef: 0.6688\n",
      "Epoch 00011: early stopping\n"
     ]
    }
   ],
   "source": [
    "# TODO : Try to train unet-2 with 250 epoch and focal tversky loss and check for overfit\n",
    "# Hyperparameters to tweak : Alpha and Gamma from focal tversky loss for accuracy, and dropout rate for overfit\n",
    "metrics=[tf.keras.metrics.Precision(),\n",
    "         tf.keras.metrics.Recall(),\n",
    "         dice_coef\n",
    "        ]\n",
    "callbacks = [\n",
    "             tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10, verbose=1),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5)\n",
    "            ]\n",
    "if RESTORE_MODEL:\n",
    "    model = tf.keras.models.load_model(SAVE_DIR\n",
    "    , custom_objects={'dice_coef_loss': dice_coef_loss, 'dice_coef': dice_coef})\n",
    "else:  \n",
    "    model = model_function()\n",
    "    model.compile(optimizer='adam',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=metrics)\n",
    "    history = model.fit(X_train, y_train, \n",
    "                        epochs = NUM_EPOCHS,\n",
    "                        validation_split=VALIDATION_SIZE,\n",
    "                        callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fon8F-kTFwc5",
    "outputId": "9c2d04c6-be66-4784-edcd-b75663c1eb02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: model_save/cnn_6conv/assets\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    model.save(SAVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "8qu-WoHlGkop"
   },
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    train_predictions = model.predict(X_train).squeeze()\n",
    "    test_predictions = model.predict(X_test).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "id": "lmPta9mIGkoq",
    "outputId": "7fe9e91b-8618-46e4-9498-7215efe9cdd7"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-a2351bebad1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvisualize_random_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/content/drive/Shareddrives/ML_Road_Segmentation/CS-433-project-2/project_road_segmentation/helpers/prediction_checking.py\u001b[0m in \u001b[0;36mvisualize_random_predictions\u001b[0;34m(x, y, predictions, size)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mROAD_THRESHOLD_PIXEL_PRED\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mimg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcatenate_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_to_rgb_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mimg2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcatenate_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_to_rgb_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mimg3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcatenate_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_to_rgb_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/drive/Shareddrives/ML_Road_Segmentation/CS-433-project-2/project_road_segmentation/helpers/image_processing.py\u001b[0m in \u001b[0;36mconcatenate_images\u001b[0;34m(img1, img2)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconcatenate_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 1 has 2 dimension(s)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_random_predictions(X_train, y_train, train_predictions, size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pNjSbUq7Gkox"
   },
   "outputs": [],
   "source": [
    "visualize_random_predictions(X_test, y_test, test_predictions, size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "8zNdrauVGkoy",
    "outputId": "11d0645f-e324-4636-d8b6-9fc5cca099ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: model_save/cnn_6conv/ (stored 0%)\n",
      "  adding: model_save/cnn_6conv/variables/ (stored 0%)\n",
      "  adding: model_save/cnn_6conv/variables/variables.data-00000-of-00001 (deflated 52%)\n",
      "  adding: model_save/cnn_6conv/variables/variables.index (deflated 71%)\n",
      "  adding: model_save/cnn_6conv/assets/ (stored 0%)\n",
      "  adding: model_save/cnn_6conv/saved_model.pb (deflated 90%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_fa634709-9399-49d3-b5c2-7742d34d9d21\", \"cnn_6conv.zip\", 12479632)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if True:\n",
    "    from helpers.colab import download_model\n",
    "    from google.colab import files\n",
    "    download_model(MODEL_NAME, SAVE_DIR, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LBOlXskdOvpI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "pipeline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
