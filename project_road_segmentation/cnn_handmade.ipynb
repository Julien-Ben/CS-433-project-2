{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T17:34:42.009863Z",
     "start_time": "2020-11-02T17:34:38.441520Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T17:34:42.078089Z",
     "start_time": "2020-11-02T17:34:42.012507Z"
    }
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os\n",
    "import sys\n",
    "import urllib\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "\n",
    "import code\n",
    "\n",
    "import tensorflow.python.platform\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T17:34:42.148400Z",
     "start_time": "2020-11-02T17:34:42.081451Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T17:34:42.213803Z",
     "start_time": "2020-11-02T17:34:42.151668Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.append('./')\n",
    "from helpers.helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T17:34:42.276021Z",
     "start_time": "2020-11-02T17:34:42.216131Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_CHANNELS = 3  # RGB images\n",
    "PIXEL_DEPTH = 255\n",
    "NUM_LABELS = 2\n",
    "TRAINING_SIZE = 20\n",
    "VALIDATION_SIZE = 5  # Size of the validation set.\n",
    "SEED = 66478  # Set to None for random seed.\n",
    "BATCH_SIZE = 16  # 64\n",
    "NUM_EPOCHS = 100\n",
    "RESTORE_MODEL = True  # If True, restore existing model instead of training a new one\n",
    "RECORDING_STEP = 0\n",
    "\n",
    "# Set image patch size in pixels\n",
    "# IMG_PATCH_SIZE should be a multiple of 4\n",
    "# image size should be an integer multiple of this number!\n",
    "IMG_PATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T17:34:43.190864Z",
     "start_time": "2020-11-02T17:34:42.278670Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data/training/images/satImage_001.png\n",
      "Loading data/training/images/satImage_002.png\n",
      "Loading data/training/images/satImage_003.png\n",
      "Loading data/training/images/satImage_004.png\n",
      "Loading data/training/images/satImage_005.png\n",
      "Loading data/training/images/satImage_006.png\n",
      "Loading data/training/images/satImage_007.png\n",
      "Loading data/training/images/satImage_008.png\n",
      "Loading data/training/images/satImage_009.png\n",
      "Loading data/training/images/satImage_010.png\n",
      "Loading data/training/images/satImage_011.png\n",
      "Loading data/training/images/satImage_012.png\n",
      "Loading data/training/images/satImage_013.png\n",
      "Loading data/training/images/satImage_014.png\n",
      "Loading data/training/images/satImage_015.png\n",
      "Loading data/training/images/satImage_016.png\n",
      "Loading data/training/images/satImage_017.png\n",
      "Loading data/training/images/satImage_018.png\n",
      "Loading data/training/images/satImage_019.png\n",
      "Loading data/training/images/satImage_020.png\n",
      "Loading data/training/groundtruth/satImage_001.png\n",
      "Loading data/training/groundtruth/satImage_002.png\n",
      "Loading data/training/groundtruth/satImage_003.png\n",
      "Loading data/training/groundtruth/satImage_004.png\n",
      "Loading data/training/groundtruth/satImage_005.png\n",
      "Loading data/training/groundtruth/satImage_006.png\n",
      "Loading data/training/groundtruth/satImage_007.png\n",
      "Loading data/training/groundtruth/satImage_008.png\n",
      "Loading data/training/groundtruth/satImage_009.png\n",
      "Loading data/training/groundtruth/satImage_010.png\n",
      "Loading data/training/groundtruth/satImage_011.png\n",
      "Loading data/training/groundtruth/satImage_012.png\n",
      "Loading data/training/groundtruth/satImage_013.png\n",
      "Loading data/training/groundtruth/satImage_014.png\n",
      "Loading data/training/groundtruth/satImage_015.png\n",
      "Loading data/training/groundtruth/satImage_016.png\n",
      "Loading data/training/groundtruth/satImage_017.png\n",
      "Loading data/training/groundtruth/satImage_018.png\n",
      "Loading data/training/groundtruth/satImage_019.png\n",
      "Loading data/training/groundtruth/satImage_020.png\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'data/training/'\n",
    "train_data_filename = data_dir + 'images/'\n",
    "train_labels_filename = data_dir + 'groundtruth/' \n",
    "\n",
    "# Extract it into numpy arrays.\n",
    "train_data = extract_data(train_data_filename, TRAINING_SIZE)\n",
    "train_labels = extract_labels(train_labels_filename, TRAINING_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T17:34:43.387206Z",
     "start_time": "2020-11-02T17:34:43.193021Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points per class: c0 = 9450 c1 = 3050\n",
      "Balancing training data...\n",
      "6100\n",
      "(12500, 16, 16, 3)\n",
      "Number of data points per class: c0 = 3050 c1 = 3050\n"
     ]
    }
   ],
   "source": [
    "num_epochs = NUM_EPOCHS\n",
    "\n",
    "c0 = 0  # bgrd\n",
    "c1 = 0  # road\n",
    "for i in range(len(train_labels)):\n",
    "    if train_labels[i][0] == 1:\n",
    "        c0 = c0 + 1\n",
    "    else:\n",
    "        c1 = c1 + 1\n",
    "print('Number of data points per class: c0 = ' + str(c0) + ' c1 = ' + str(c1))\n",
    "\n",
    "print('Balancing training data...')\n",
    "min_c = min(c0, c1)\n",
    "idx0 = [i for i, j in enumerate(train_labels) if j[0] == 1]\n",
    "idx1 = [i for i, j in enumerate(train_labels) if j[1] == 1]\n",
    "new_indices = idx0[0:min_c] + idx1[0:min_c]\n",
    "print(len(new_indices))\n",
    "print(train_data.shape)\n",
    "train_data = train_data[new_indices, :, :, :]\n",
    "train_labels = train_labels[new_indices]\n",
    "\n",
    "train_size = train_labels.shape[0]\n",
    "\n",
    "c0 = 0\n",
    "c1 = 0\n",
    "for i in range(len(train_labels)):\n",
    "    if train_labels[i][0] == 1:\n",
    "        c0 = c0 + 1\n",
    "    else:\n",
    "        c1 = c1 + 1\n",
    "print('Number of data points per class: c0 = ' + str(c0) + ' c1 = ' + str(c1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T17:34:43.466335Z",
     "start_time": "2020-11-02T17:34:43.394475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6100, 16, 16, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T17:34:44.215197Z",
     "start_time": "2020-11-02T17:34:43.471454Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "if RESTORE_MODEL:\n",
    "    # It can be used to reconstruct the model identically.\n",
    "    model = models.load_model(\"handmade_cnn_save/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T17:34:44.285450Z",
     "start_time": "2020-11-02T17:34:44.217706Z"
    }
   },
   "outputs": [],
   "source": [
    "if not RESTORE_MODEL:\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (5, 5), activation='relu', input_shape=(16, 16, 3), padding='same', use_bias=True))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (5, 5), activation='relu', input_shape=(8, 8, 3), padding='same', use_bias=True))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T17:34:44.357552Z",
     "start_time": "2020-11-02T17:34:44.287745Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 32)        2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 64)          51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                65600     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 119,426\n",
      "Trainable params: 119,426\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T18:14:47.761502Z",
     "start_time": "2020-11-02T18:14:14.911531Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6100 samples\n",
      "Epoch 1/10\n",
      "6100/6100 [==============================] - 3s 542us/sample - loss: 0.0269 - accuracy: 0.9900\n",
      "Epoch 2/10\n",
      "6100/6100 [==============================] - 3s 462us/sample - loss: 0.0525 - accuracy: 0.9808\n",
      "Epoch 3/10\n",
      "6100/6100 [==============================] - 3s 561us/sample - loss: 0.0106 - accuracy: 0.9972\n",
      "Epoch 4/10\n",
      "6100/6100 [==============================] - 3s 495us/sample - loss: 0.0212 - accuracy: 0.9934\n",
      "Epoch 5/10\n",
      "6100/6100 [==============================] - 3s 522us/sample - loss: 0.0423 - accuracy: 0.9846\n",
      "Epoch 6/10\n",
      "6100/6100 [==============================] - 3s 509us/sample - loss: 0.0069 - accuracy: 0.9989\n",
      "Epoch 7/10\n",
      "6100/6100 [==============================] - 3s 491us/sample - loss: 0.0124 - accuracy: 0.9952\n",
      "Epoch 8/10\n",
      "6100/6100 [==============================] - 3s 513us/sample - loss: 0.0608 - accuracy: 0.9790\n",
      "Epoch 9/10\n",
      "6100/6100 [==============================] - 3s 536us/sample - loss: 0.0583 - accuracy: 0.9800\n",
      "Epoch 10/10\n",
      "6100/6100 [==============================] - 3s 471us/sample - loss: 0.0085 - accuracy: 0.9977\n",
      "INFO:tensorflow:Assets written to: handmade_cnn_save/assets\n"
     ]
    }
   ],
   "source": [
    "if not RESTORE_MODEL: \n",
    "    model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    history = model.fit(train_data, train_labels, epochs=10) #,validation_data=(test_images, test_labels)\n",
    "    model.save(\"handmade_cnn_save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-02T18:25:05.026566Z",
     "start_time": "2020-11-02T18:25:04.959871Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(\"Running prediction on training set\")\n",
    "# prediction_training_dir = \"predictions_training/\"\n",
    "# if not os.path.isdir(prediction_training_dir):\n",
    "#     os.mkdir(prediction_training_dir)\n",
    "# for i in range(1, TRAINING_SIZE + 1):\n",
    "#     pimg = get_prediction_with_groundtruth(model, train_data_filename, i)\n",
    "#     Image.fromarray(pimg).save(prediction_training_dir + \"prediction_\" + str(i) + \".png\")\n",
    "#     oimg = get_prediction_with_overlay(model, train_data_filename, i)\n",
    "#     oimg.save(prediction_training_dir + \"overlay_\" + str(i) + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
